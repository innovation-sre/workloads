---
###############################################################################
# Ansible SSH variables.
###############################################################################
ansible_public_key_file: "{{ lookup('env', 'PUBLIC_KEY')|default('~/.ssh/id_rsa.pub', true) }}"
ansible_private_key_file: "{{ lookup('env', 'PRIVATE_KEY')|default('~/.ssh/id_rsa', true) }}"

orchestration_user: "{{ lookup('env', 'ORCHESTRATION_USER')|default('root', true) }}"
###############################################################################
# HTTP workload variables.
###############################################################################
workload_image: "{{ lookup('env', 'WORKLOAD_IMAGE')|default('quay.io/openshift-scale/scale-ci-workload:master', true) }}"

workload_job_node_selector: "{{ lookup('env', 'WORKLOAD_JOB_NODE_SELECTOR')|default(true, true)|bool }}"
workload_job_taint: "{{ lookup('env', 'WORKLOAD_JOB_TAINT')|default(true, true)|bool }}"

kubeconfig_file: "{{ lookup('env', 'KUBECONFIG_FILE')|default('~/.kube/config', true) }}"

# pbench variables
pbench_ssh_private_key_file: "{{ lookup('env', 'PBENCH_SSH_PRIVATE_KEY_FILE')|default('~/.ssh/id_rsa', true) }}"
pbench_ssh_public_key_file: "{{ lookup('env', 'PBENCH_SSH_PUBLIC_KEY_FILE')|default('~/.ssh/id_rsa.pub', true) }}"
enable_pbench_agents: "{{ lookup('env', 'ENABLE_PBENCH_AGENTS')|default(false, true)|bool }}"
pbench_server: "{{ lookup('env', 'PBENCH_SERVER')|default('', true) }}"

# Other variables for workload tests
scale_ci_results_token: "{{ lookup('env', 'SCALE_CI_RESULTS_TOKEN')|default('', true) }}"
job_completion_poll_attempts: "{{ lookup('env', 'JOB_COMPLETION_POLL_ATTEMPTS')|default(1000, true)|int }}"
workload_script_config: "scale-ci-http-script"
# HTTP workload specific parameters
enable_pbench_copy: "{{ lookup('env', 'ENABLE_PBENCH_COPY')|default('', true) }}"
http_env_vars: [
  "ES_SERVER",
  "ES_PORT",
  "EMAIL_ID_FOR_RESULTS_SHEET",
  "GSHEET_KEY",
  "COMPARE_RESULTS",
  "BASELINE_RESULTS_TARBALL",
  "COMPARISON_TOLERANCE",
  "HTTP_TEST_SUFFIX",
  "HTTP_TEST_LOAD_GENERATORS",
  "HTTP_TEST_LOAD_GENERATOR_NODES",
  "HTTP_TEST_APP_PROJECTS",
  "HTTP_TEST_APP_TEMPLATES",
  "HTTP_TEST_RUNTIME",
  "HTTP_TEST_MB_RAMP_UP",
  "HTTP_TEST_MB_DELAY",
  "HTTP_TEST_MB_TLS_SESSION_REUSE",
  "HTTP_TEST_MB_METHOD",
  "HTTP_TEST_MB_RESPONSE_SIZE",
  "HTTP_TEST_MB_REQUEST_BODY_SIZE",
  "HTTP_TEST_ROUTE_TERMINATION",
  "HTTP_TEST_SMOKE_TEST",
  "HTTP_TEST_NAMESPACE_CLEANUP",
  "HTTP_TEST_STRESS_CONTAINER_IMAGE",
  "HTTP_TEST_SERVER_CONTAINER_IMAGE"
]
workload_nodeselector: "{{ lookup('env', 'WORKLOAD_NODESELECTOR')|default('', true) }}"

#Prometheus vars
workload_name: "http"
job_name: "{{ lookup('env', 'JOB_NAME')|lower()|default('', true) }}"
job_url: "{{ lookup('env', 'JOB_URL')|default('', true) }}"
build_number: "{{ lookup('env', 'BUILD_NUMBER')|default('', true) }}"
workspace: "{{ lookup('env', 'WORKSPACE')|default('', true) }}"
post_workload_sleep_time: "{{ lookup('env', 'POST_WORKLOAD_SLEEP_TIME')|default(180, true) | int }}"
promql_queries:
  - name: "https-reencrypt-total"
    expr: "sum(rate(haproxy_server_http_responses_total{route=~'nginx-reencrypt-001', exported_namespace=~'server-tls-reencrypt-[0-9]+'}[1m])) by (instance)"
    interval: "30s"
    step: "60"
    print: "yes"
    title: "HTTPS Re-Encrypt Total"
    description: "Re-Encrypt HTTP at the nginx Server"
    x_label: "Time in minutes"
    y_label: "Number of requests per second"
  - name: "https-reencrypt-error-rate"
    expr: "sum(rate(haproxy_server_response_errors_total{route=~'nginx-reencrypt-001', exported_namespace=~'server-tls-reencrypt-[0-9]+'}[1m]) * 60) / sum(rate(haproxy_server_http_responses_total{route=~'nginx-reencrypt-001', exported_namespace=~'server-tls-reencrypt-[0-9]+'}[1m]) * 60)"
    interval: "30s"
    step: "60"
    print: "yes"
    title: "HTTPS Re-Encrypt Error Rate"
    description: "Re-Encrypt HTTP Error Rate at the nginx Server"
    x_label: "Time in minutes"
    y_label: "Number of errors per second"
  - name: "https-edge-total"
    expr: "sum(rate(haproxy_server_http_responses_total{route=~'nginx-edge-001', exported_namespace=~'server-tls-edge-[0-9]+'}[1m])) by (instance)"
    interval: "30s"
    step: "60"
    print: "yes"
    title: "HTTPS Edge Total"
    description: "HTTP Termination at the Edge"
    x_label: "Time in minutes"
    y_label: "Number of requests per second"
  - name: "https-edge-error-rate"
    expr: "sum(rate(haproxy_server_response_errors_total{route=~'nginx-edge-001', exported_namespace=~'server-tls-edge-[0-9]+'}[1m]) * 60) / sum(rate(haproxy_server_http_responses_total{route=~'nginx-edge-001', exported_namespace=~'server-tls-edge-[0-9]+'}[1m]) * 60)"
    interval: "30s"
    step: "60"
    print: "yes"
    title: "HTTPS Edge Error Rate"
    description: "Edge HTTP Error Rate at the nginx Server"
    x_label: "Time in minutes"
    y_label: "Number of errors per second"
  - name: "https-passthrough-total"
    expr: "sum(rate(haproxy_server_http_responses_total{route=~'nginx-passthrough-001', exported_namespace=~'server-tls-passthrough-[0-9]+'}[1m])) by (instance)"
    interval: "30s"
    step: "60"
    print: "yes"
    title: "HTTPS Passthrough Total"
    description: "HTTPS Passthrough Test"
    x_label: "Time in minutes"
    y_label: "Number of requests per second"
  - name: "https-passthrough-error-rate"
    expr: "sum(rate(haproxy_server_response_errors_total{route=~'nginx-passthrough-001', exported_namespace=~'server-tls-passthrough-[0-9]+'}[1m]) * 60) / sum(rate(haproxy_server_http_responses_total{route=~'nginx-passthrough-001', exported_namespace=~'server-tls-passthrough-[0-9]+'}[1m]) * 60)"
    interval: "30s"
    step: "60"
    print: "yes"
    title: "HTTPS Passthrough Error Rate"
    description: "Passthrough HTTP Error Rate at the nginx Server"
    x_label: "Time in minutes"
    y_label: "Number of errors per second"
  - name: "http-total"
    expr: "sum(rate(haproxy_server_http_responses_total{route=~'nginx-http-001', exported_namespace=~'server-http-[0-9]+'}[1m])) by (instance)"
    interval: "30s"
    step: "60"
    print: "yes"
    title: "HTTP Edge Total"
    description: "HTTP Termination at the Edge"
    x_label: "Time in minutes"
    y_label: "Number of requests per second"
  - name: "http-error-rate"
    expr: "sum(rate(haproxy_server_response_errors_total{route=~'nginx-http-001', exported_namespace=~'server-http-[0-9]+'}[1m]) * 60) / sum(rate(haproxy_server_http_responses_total{route=~'nginx-http-001', exported_namespace=~'server-http-[0-9]+'}[1m]) * 60)"
    interval: "30s"
    step: "60"
    print: "yes"
    title: "HTTPS Passthrough Error Rate"
    description: "Passthrough HTTP Error Rate at the nginx Server"
    x_label: "Time in minutes"
    y_label: "Number of errors per second"
  - name: "qps-master-node"
    expr: "sum by (instance) (rate(apiserver_request_total{}[1m]))"
    interval: "30s"
    step: "60"
    print: "yes"
    title: "API Requests/sec"
    description: "Requests per sec on the Kubernetes API Server"
    x_label: "Time in minutes"
    y_label: "Number of requests per second"
  - name: "success-rate"
    expr: "sum by (instance) (rate(apiserver_request_total{code=~'[2]..'}[1m]))"
    interval: "30s"
    step: "60"
    print: "yes"
    title: "API Success Rate"
    description: "Success rate for the requests to the Kubernetes API Server"
    x_label: "Time in minutes"
    y_label: "Number of successful requests per sec"
  - name: "error-rate"
    expr: "sum by (instance) (rate(apiserver_request_total{code=~'[5]..'}[1m]))"
    interval: "30s"
    step: "60"
    print: "yes"
    title: "API Error Rate"
    description: "Error rate for the requests to the Kubernetes API Server"
    x_label: "Time in minutes"
    y_label: "Number of bad requests per sec"
  - name: "successful-pods"
    expr: "sum(kubelet_running_pod_count{node!~'master.*'}) by (node)"
    interval: "30s"
    step: "60"
    print: "yes"
    title: "Successful Pods By Node"
    description: "Number of Running Pods"
    x_label: "Time in minutes"
    y_label: "Number of successful pods"
  - name: "successful-pods-1"
    expr: "sum(kubelet_running_pod_count{node!~'master.*'})"
    interval: "30s"
    step: "60"
    print: "yes"
    title: "Successful Pods Total"
    description: "Number of Running Pods"
    x_label: "Time in minutes"
    y_label: "Number of successful pods"
  - name: "failed-pods"
    expr: "sum by (namespace, instance) (kube_pod_status_phase{job='kube-state-metrics', phase=~'Failed'})"
    interval: "30s"
    step: "60"
    print: "yes"
    title: "Failed Pods By Namespace"
    description: "Number of Failed Pods"
    x_label: "Time in minutes"
    y_label: "Number of failed pods"
  - name: "failed-pods-1"
    expr: "sum(kube_pod_status_phase{job='kube-state-metrics', phase=~'Failed'})"
    interval: "30s"
    step: "60"
    print: "yes"
    title: "Failed Pods Total"
    description: "Number of Failed Pods"
    x_label: "Time in minutes"
    y_label: "Number of failed pods"
# haproxy_backend_connection_errors_total{route=~"nginx-http.*|nginx-edge.*|nginx-passthrough.*",backend=~"http.*"}
# haproxy_backend_connections_total{route=~"nginx-http.*|nginx-edge.*|nginx-passthrough.*",backend=~"http.*"}
enable_prometheus_queries: "{{ lookup('env', 'ENABLE_PROMETHEUS_QUERIES')|default(true, true)|bool }}"