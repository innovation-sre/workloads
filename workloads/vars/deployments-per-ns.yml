---
###############################################################################
# Ansible SSH variables.
###############################################################################
ansible_public_key_file: "{{ lookup('env', 'PUBLIC_KEY')|default('~/.ssh/id_rsa.pub', true) }}"
ansible_private_key_file: "{{ lookup('env', 'PRIVATE_KEY')|default('~/.ssh/id_rsa', true) }}"

orchestration_user: "{{ lookup('env', 'ORCHESTRATION_USER')|default('root', true) }}"
###############################################################################
# Deployments per namespace cluster limits workload variables.
###############################################################################
# snafu es variables
snafu_es_host: "{{ lookup('env', 'ES_HOST')|default('', true) }}"
snafu_es_port: "{{ lookup('env', 'ES_PORT')|default('', true) }}"
snafu_es_index_prefix: "{{ lookup('env', 'ES_INDEX_PREFIX')|default('snafu', true) }}"
snafu_cluster_name: "{{ lookup('env', 'SNAFU_CLUSTER_NAME')|default('', true) }}"
snafu_user: "{{ lookup('env', 'SNAFU_USER')|default('scale-ci', true) }}"

# Container image in use
workload_image: "{{ lookup('env', 'WORKLOAD_IMAGE')|default('quay.io/openshift-scale/scale-ci-workload:master', true) }}"

# Use nodeselector to place workload job on specific node
workload_job_node_selector: "{{ lookup('env', 'WORKLOAD_JOB_NODE_SELECTOR')|default(true, true)|bool }}"
# Tolerate taint on workload driver
workload_job_taint: "{{ lookup('env', 'WORKLOAD_JOB_TAINT')|default(true, true)|bool }}"
# Privileged job container
workload_job_privileged: "{{ lookup('env', 'WORKLOAD_JOB_PRIVILEGED')|default(true, true)|bool }}"

# Kubeconfig for tooling container script
kubeconfig_file: "{{ lookup('env', 'KUBECONFIG_FILE')|default('~/.kube/config', true) }}"

# pbench variables
pbench_ssh_private_key_file: "{{ lookup('env', 'PBENCH_SSH_PRIVATE_KEY_FILE')|default('~/.ssh/id_rsa', true) }}"
pbench_ssh_public_key_file: "{{ lookup('env', 'PBENCH_SSH_PUBLIC_KEY_FILE')|default('~/.ssh/id_rsa.pub', true) }}"
enable_pbench_agents: "{{ lookup('env', 'ENABLE_PBENCH_AGENTS')|default(false, true)|bool }}"
pbench_server: "{{ lookup('env', 'PBENCH_SERVER')|default('', true) }}"

# Azure auth vars to set for ocp on azure
azure_auth: "{{ lookup('env', 'AZURE_AUTH')|default(false, true)|bool|lower }}"
azure_auth_file: "{{ lookup('env', 'AZURE_AUTH_FILE')|default('', true) }}"

# Other variables for workload tests
scale_ci_results_token: "{{ lookup('env', 'SCALE_CI_RESULTS_TOKEN')|default('', true) }}"
job_completion_poll_attempts: "{{ lookup('env', 'JOB_COMPLETION_POLL_ATTEMPTS')|default(360, true)|int }}"

# Deployments per namespace cluster limis workload specific parameters:
deployments_per_ns_test_prefix: "{{ lookup('env', 'DEPLOYMENTS_PER_NS_TEST_PREFIX')|default('deployments-per-ns', true) }}"
deployments_per_ns_cleanup: "{{ lookup('env', 'DEPLOYMENTS_PER_NS_CLEANUP')|default(true, true)|bool|lower }}"
deployments_per_ns_basename: "{{ lookup('env', 'DEPLOYMENTS_PER_NS_BASENAME')|default('deployments-per-ns', true) }}"
deployments_per_ns_count: "{{ lookup('env', 'DEPLOYMENTS_PER_NS_COUNT')|default(2000, true)|int }}"
deployments_per_ns_pod_image: "{{ lookup('env', 'DEPLOYMENTS_PER_NS_POD_IMAGE')|default('gcr.io/google_containers/pause-amd64:3.0', true) }}"
workload_nodeselector: "{{ lookup('env', 'WORKLOAD_NODESELECTOR')|default('', true) }}"
workload_script_config: "scale-ci-deployments-per-ns-script"

#Prometheus vars
workload_name: "nodevertical"
job_name: "{{ lookup('env', 'JOB_NAME')|lower()|default('', true) }}"
job_url: "{{ lookup('env', 'JOB_URL')|default('', true) }}"
build_number: "{{ lookup('env', 'BUILD_NUMBER')|default('', true) }}"
workspace: "{{ lookup('env', 'WORKSPACE')|default('', true) }}"
post_workload_sleep_time: "{{ lookup('env', 'POST_WORKLOAD_SLEEP_TIME')|default(180, true) | int }}"
promql_queries:
  - name: "etcd-object-count"
    expr: "sum(rate(etcd_object_counts{}[1m]))"
    interval: "30s"
    step: "60"
    print: "yes"
    title: "etcd Object Count"
    description: "Object count for etcd key/value per sec"
    x_label: "Time in minutes"
    y_label: "Number of object per second"
  - name: "etcd-commit-duration"
    expr: "histogram_quantile(0.99, sum(rate(etcd_disk_backend_commit_duration_seconds_bucket{}[1m])) by (le))"
    interval: "30s"
    step: "60"
    print: "yes"
    title: "etcd Commit Duration"
    description: "Commit Duration for etcd"
    x_label: "Time in minutes"
    y_label: "Latency in seconds"
  - name: "etcd-fsync-duration"
    expr: "histogram_quantile(0.99, sum(rate(etcd_disk_wal_fsync_duration_seconds_bucket{}[1m])) by (le))"
    interval: "30s"
    step: "60"
    print: "yes"
    title: "etcd fSync Duration"
    description: "fSync Duration for etcd"
    x_label: "Time in minutes"
    y_label: "Latency in seconds"
  - name: "scheduling-latency"
    expr: "cluster_quantile:scheduler_e2e_scheduling_duration_seconds:histogram_quantile{quantile='0.99'}"
    interval: "30s"
    step: "60"
    print: "yes"
    title: "Scheduling Latency"
    description: "Scheduling Latency for Pods"
    x_label: "Time in minutes"
    y_label: "Latency in seconds"
  - name: "kubelet-start-latency"
    expr: "rate(kubelet_pod_start_latency_microseconds_sum[1m]) * 1e-6"
    interval: "30s"
    step: "60"
    print: "yes"
    title: "Kubelet Pod Startup Latency"
    description: "Time in seconds"
    x_label: "Time in minutes"
    y_label: "Latency in seconds"
  - name: "api-response-latency"
    expr: "histogram_quantile(0.99, sum(rate(apiserver_request_duration_seconds_bucket{verb=~'CREATE|DELETE|GET|LIST|PATCH|POST|PUT|UPDATE'}[1m])) by (verb, le))"
    interval: "30s"
    step: "60"
    print: "yes"
    title: "API Server Response Latency"
    description: "Latency for API Server"
    x_label: "Time in minutes"
    y_label: "Latency"
  - name: "qps-master-node"
    expr: "sum by (instance) (rate(apiserver_request_total{}[1m]))"
    interval: "30s"
    step: "60"
    print: "yes"
    title: "API Requests/sec"
    description: "Requests per sec on the Kubernetes API Server"
    x_label: "Time in minutes"
    y_label: "Number of requests per second"
  - name: "success-rate"
    expr: "sum by (instance) (rate(apiserver_request_total{code=~'[2]..'}[1m]))"
    interval: "30s"
    step: "60"
    print: "yes"
    title: "API Success Rate"
    description: "Success rate for the requests to the Kubernetes API Server"
    x_label: "Time in minutes"
    y_label: "Number of successful requests per sec"
  - name: "error-rate"
    expr: "sum by (instance) (rate(apiserver_request_total{code=~'[5]..'}[1m]))"
    interval: "30s"
    step: "60"
    print: "yes"
    title: "API Error Rate"
    description: "Error rate for the requests to the Kubernetes API Server"
    x_label: "Time in minutes"
    y_label: "Number of bad requests per sec"
  - name: "namespaces-count"
    expr: "count(kube_namespace_created)"
    interval: "30s"
    step: "60"
    print: "yes"
    title: "Namespace created"
    description: "Number of Namespaces Created"
    x_label: "Time in minutes"
    y_label: "Number of namespaces"
  - name: "successful-pods"
    expr: "sum(kubelet_running_pod_count{node!~'master.*'}) by (node)"
    interval: "30s"
    step: "60"
    print: "yes"
    title: "Successful Pods By Node"
    description: "Number of Running Pods"
    x_label: "Time in minutes"
    y_label: "Number of successful pods"
  - name: "successful-pods-1"
    expr: "sum(kubelet_running_pod_count{node!~'master.*'})"
    interval: "30s"
    step: "60"
    print: "yes"
    title: "Successful Pods Total"
    description: "Number of Running Pods"
    x_label: "Time in minutes"
    y_label: "Number of successful pods"
  - name: "failed-pods"
    expr: "sum by (namespace) (kube_pod_status_phase{job='kube-state-metrics', phase=~'Failed'}) > 0"
    interval: "30s"
    step: "60"
    print: "yes"
    title: "Failed Pods By Namespace"
    description: "Number of Failed Pods"
    x_label: "Time in minutes"
    y_label: "Number of failed pods"
  - name: "failed-pods-1"
    expr: "sum(kube_pod_status_phase{job='kube-state-metrics', phase=~'Failed'})"
    interval: "30s"
    step: "60"
    print: "yes"
    title: "Failed Pods Total"
    description: "Number of Failed Pods"
    x_label: "Time in minutes"
    y_label: "Number of failed pods"
# Enable generating reports
enable_prometheus_queries: "{{ lookup('env', 'ENABLE_PROMETHEUS_QUERIES')|default(true, true)|bool }}"